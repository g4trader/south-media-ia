#!/usr/bin/env python3
"""
Extrator Funcional para Dados de Campanha de V√≠deo
Vers√£o que realmente funciona
"""

import os
import sys
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, List
import logging
import re

# Adicionar diret√≥rio raiz ao path
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from google_sheets_service import GoogleSheetsService
from numeric_parsers import safe_float as parse_safe_float, safe_int as parse_safe_int

logger = logging.getLogger(__name__)


PUBLISHER_COLUMN_CANDIDATES = [
    "publisher",
    "publisher name",
    "publisher_name",
    "publisher/ exchange",
    "publisher / exchange",
    "publisher label",
    "exchange",
    "inventory",
    "inventory source",
    "inventory_source",
    "site",
    "site name",
    "site_name",
    "channel",
    "channel name",
    "canal",
    "ve√≠culo",
    "veiculo",
    "vehicle",
    "placement",
    "placement name",
    "placement_name",
    "publisher id",
    "publisher_id"
]

PUBLISHER_TYPE_COLUMN_CANDIDATES = [
    "type",
    "publisher type",
    "publisher_type",
    "site type",
    "site_type",
    "channel type",
    "channel_type"
]

DAY_COLUMN_CANDIDATES = [
    "day",
    "date",
    "data",
]

CREATIVE_COLUMN_CANDIDATES = [
    "creative",
    "criativo",
    "ad",
    "ad name",
    "ad_name",
]

SPEND_COLUMN_CANDIDATES = [
    "valor investido",
    "valor investido (r$)",
    "investimento",
    "budget",
    "spend",
]

IMPRESSIONS_COLUMN_CANDIDATES = [
    "imps",
    "impressions",
    "impress√µes",
    "impressoes",
]

CLICKS_COLUMN_CANDIDATES = [
    "clicks",
    "cliques",
]

CPV_COLUMN_CANDIDATES = [
    "cpv",
    "cost per view",
]

CTR_COLUMN_CANDIDATES = [
    "ctr",
    "ctr ",
    "click-through rate",
]

VIDEO_STARTS_COLUMN_CANDIDATES = [
    "video starts",
    "starts",
    "video start",
    "in√≠cios de v√≠deo",
    "inicios de video",
]

VIDEO_COMPLETIONS_COLUMN_CANDIDATES = [
    "100%  video complete",
    "100% video complete",
    "video completions",
    "video assistido 100%",
    "complete views",
    "completed views",
]


def _normalize_sheet_value(value) -> Optional[str]:
    """Return a stripped string representation for sheet values."""

    if value is None or (isinstance(value, float) and pd.isna(value)):
        return None

    text = str(value).strip()
    if not text or text.lower() == "nan":
        return None
    return text


def _extract_row_value(
    row: pd.Series,
    candidates,
    normalized_columns: Optional[Dict[str, str]] = None,
) -> Optional[str]:
    """Retrieve the first non-empty value from the provided candidate columns."""

    if not isinstance(row, pd.Series):
        return None

    normalized_columns = normalized_columns or {
        str(col).strip().lower(): col for col in row.index
    }

    for candidate in candidates:
        normalized_candidate = str(candidate).strip().lower()
        source_column = normalized_columns.get(normalized_candidate)
        if source_column is None:
            continue

        value = _normalize_sheet_value(row.get(source_column))
        if value is not None:
            return value

    return None


def _extract_candidate_value(
    row: pd.Series,
    normalized_columns: Dict[str, str],
    candidates: List[str],
):
    """Return the first non-null value for any of the candidate columns."""

    if not isinstance(row, pd.Series) or not normalized_columns:
        return None

    for candidate in candidates:
        normalized_candidate = str(candidate).strip().lower()
        source_column = normalized_columns.get(normalized_candidate)
        if source_column is None:
            continue

        value = row.get(source_column)
        if value is None:
            continue

        if isinstance(value, float) and pd.isna(value):
            continue

        if isinstance(value, str) and not value.strip():
            continue

        return value

    return None


def _slugify_publisher(name: str) -> str:
    """Create a simple slug for publisher descriptions."""

    if not name:
        return "publisher"

    slug = "-".join(
        part for part in re.split(r"[^a-z0-9]+", name.lower()) if part
    )
    return slug or "publisher"

class WorkingVideoExtractor:
    """Extrator que realmente funciona"""
    
    def __init__(self, config):
        self.config = config
        self.sheets_service = GoogleSheetsService()
        
    def extract_data(self) -> Optional[Dict[str, Any]]:
        """Extrair dados da planilha - VERS√ÉO QUE FUNCIONA"""
        try:
            logger.info(f"üîÑ Iniciando extra√ß√£o REAL para {self.config.client}")
            
            # 1. Verificar se o servi√ßo est√° configurado
            if not self.sheets_service.is_configured():
                logger.error("‚ùå Google Sheets n√£o configurado")
                return None
            
            # 2. Extrair dados di√°rios da aba "Report"
            daily_data = self._extract_daily_data_real()
            if not daily_data:
                logger.warning("‚ö†Ô∏è Nenhum dado di√°rio encontrado")
                return None
            
            # 3. Extrair dados de contrato
            contract_data = self._extract_contract_data_real()
            
            # 4. Calcular m√©tricas totais
            total_metrics = self._calculate_total_metrics(daily_data, contract_data)
            
            # 5. Preparar dados finais
            result = {
                "campaign_name": f"{self.config.client} - {self.config.campaign}",
                "dashboard_title": f"Dashboard {self.config.client} - {self.config.campaign}",
                "channel": "Progr√°matica",
                "creative_type": "Video",
                "period": contract_data.get("period", "15/09/2025 - 30/09/2025"),
                "contract": contract_data,
                "daily_data": daily_data,
                "total_metrics": total_metrics,
                "publishers": self._get_publishers(daily_data),
                "strategies": self._extract_strategies_data_real(),
            }
            
            logger.info(f"‚úÖ Extra√ß√£o REAL conclu√≠da: {len(daily_data)} registros di√°rios")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Erro na extra√ß√£o REAL: {e}")
            import traceback
            logger.error(f"‚ùå Traceback: {traceback.format_exc()}")
            return None

    def _get_tab_gid(self, tab_key: str) -> Optional[str]:
        """Recupera o GID configurado para uma aba espec√≠fica."""

        tabs = getattr(self.config, "tabs", None) or {}
        if not isinstance(tabs, dict):
            return None

        gid = tabs.get(tab_key)
        if gid is None:
            return None

        gid_str = str(gid).strip()
        return gid_str or None

    def _read_tab_dataframe(
        self,
        tab_key: str,
        default_sheet_name: Optional[str],
    ) -> pd.DataFrame:
        """L√™ uma aba da planilha utilizando o GID configurado."""

        gid = self._get_tab_gid(tab_key)
        if gid:
            logger.info("üìÑ Lendo aba '%s' usando GID %s", tab_key, gid)
            df = self.sheets_service.read_sheet_data(
                self.config.sheet_id,
                gid=gid,
            )

            if not df.empty or default_sheet_name is None:
                return df

            logger.warning(
                "‚ö†Ô∏è Aba '%s' (gid %s) vazia ou n√£o encontrada; tentando nome padr√£o '%s'",
                tab_key,
                gid,
                default_sheet_name,
            )

        if default_sheet_name:
            logger.info(
                "‚ÑπÔ∏è Utilizando fallback para aba '%s' com nome '%s'",
                tab_key,
                default_sheet_name,
            )
            return self.sheets_service.read_sheet_data(
                self.config.sheet_id,
                sheet_name=default_sheet_name,
            )

        return pd.DataFrame()

    def _extract_strategies_data_real(self) -> Dict[str, List[str]]:
        """Extrai dados de estrat√©gias convertendo linhas da planilha em listas."""

        empty_strategies = {
            "segmentation": [],
            "creative_strategy": [],
            "objectives": [],
            "highlights": [],
            "formats": [],
            "channels": [],
            "insights": [],
        }

        try:
            df = self._read_tab_dataframe("strategies", "Estrat√©gias")
        except Exception as error:
            logger.warning("‚ö†Ô∏è Erro ao ler aba de estrat√©gias: %s", error)
            return empty_strategies

        if df is None or df.empty:
            return empty_strategies

        strategies_data = {key: list(values) for key, values in empty_strategies.items()}

        for _, row in df.iterrows():
            row_values = [
                str(value).strip()
                for value in row
                if value is not None and not (isinstance(value, float) and pd.isna(value)) and str(value).strip()
            ]

            if len(row_values) < 2:
                continue

            category = row_values[0].lower()
            values = row_values[1:]

            if "segment" in category:
                target_key = "segmentation"
            elif "criativo" in category or "creative" in category:
                target_key = "creative_strategy"
            elif "objetivo" in category or "objective" in category:
                target_key = "objectives"
            elif "destaque" in category or "highlight" in category:
                target_key = "highlights"
            elif "formato" in category or "format" in category:
                target_key = "formats"
            elif "canal" in category or "channel" in category:
                target_key = "channels"
            elif "insight" in category:
                target_key = "insights"
            else:
                continue

            for value in values:
                cleaned_value = value.strip()
                if cleaned_value and cleaned_value.lower() != "nan":
                    strategies_data[target_key].append(cleaned_value)

        return strategies_data

    def _extract_daily_data_real(self) -> list:
        """Extrair dados di√°rios da aba Report - VERS√ÉO QUE FUNCIONA"""
        try:
            logger.info("üîÑ Extraindo dados di√°rios REAIS...")
            
            # Usar o m√©todo correto do GoogleSheetsService
            df = self._read_tab_dataframe("daily_data", "Report")
            
            if df is None or df.empty:
                logger.warning("‚ö†Ô∏è DataFrame vazio da aba Report")
                return []
            
            logger.info(f"‚úÖ DataFrame carregado: {len(df)} linhas, {len(df.columns)} colunas")
            logger.info(f"üìä Colunas dispon√≠veis: {list(df.columns)}")
            
            daily_records = []
            for index, row in df.iterrows():
                try:
                    normalized_columns = {
                        str(col).strip().lower(): col for col in row.index
                    }

                    # Extrair dados b√°sicos com tratamento de erro
                    date_value = _extract_candidate_value(
                        row, normalized_columns, DAY_COLUMN_CANDIDATES
                    )
                    date_str = str(date_value or "").strip()
                    if not date_str or date_str == 'nan' or date_str == '':
                        continue

                    creative_value = _extract_candidate_value(
                        row, normalized_columns, CREATIVE_COLUMN_CANDIDATES
                    )
                    creative = _normalize_sheet_value(creative_value) or ''
                    publisher_name = (
                        _extract_row_value(
                            row,
                            PUBLISHER_COLUMN_CANDIDATES,
                            normalized_columns,
                        )
                        or creative
                        or "Desconhecido"
                    )
                    publisher_type = _extract_row_value(
                        row, PUBLISHER_TYPE_COLUMN_CANDIDATES, normalized_columns
                    )
                    spend = self._safe_float(
                        _extract_candidate_value(
                            row, normalized_columns, SPEND_COLUMN_CANDIDATES
                        )
                    )
                    impressions = self._safe_int(
                        _extract_candidate_value(
                            row, normalized_columns, IMPRESSIONS_COLUMN_CANDIDATES
                        )
                    )
                    clicks = self._safe_int(
                        _extract_candidate_value(
                            row, normalized_columns, CLICKS_COLUMN_CANDIDATES
                        )
                    )
                    cpv = self._safe_float(
                        _extract_candidate_value(
                            row, normalized_columns, CPV_COLUMN_CANDIDATES
                        )
                    )
                    ctr = self._safe_float(
                        _extract_candidate_value(
                            row, normalized_columns, CTR_COLUMN_CANDIDATES
                        )
                    )
                    starts = self._safe_int(
                        _extract_candidate_value(
                            row, normalized_columns, VIDEO_STARTS_COLUMN_CANDIDATES
                        )
                    )
                    q100 = self._safe_int(
                        _extract_candidate_value(
                            row, normalized_columns, VIDEO_COMPLETIONS_COLUMN_CANDIDATES
                        )
                    )
                    
                    # Calcular m√©tricas derivadas
                    cpm = (spend / impressions * 1000) if impressions > 0 else 0
                    vtr = (starts / impressions * 100) if impressions > 0 else 0
                    
                    record = {
                        "date": date_str,
                        "creative": creative,
                        "publisher": publisher_name,
                        "spend": spend,
                        "impressions": impressions,
                        "clicks": clicks,
                        "ctr": ctr,
                        "cpv": cpv,
                        "cpm": cpm,
                        "starts": starts,
                        "q100": q100,
                        "vtr": vtr
                    }

                    if publisher_type:
                        record["publisher_type"] = publisher_type

                    daily_records.append(record)
                    logger.info(f"‚úÖ Registro {index + 1}: {date_str} - {creative} - R$ {spend}")
                    
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Erro ao processar linha {index}: {e}")
                    continue
            
            logger.info(f"‚úÖ {len(daily_records)} registros di√°rios extra√≠dos com SUCESSO")
            return daily_records
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao extrair dados di√°rios REAIS: {e}")
            import traceback
            logger.error(f"‚ùå Traceback: {traceback.format_exc()}")
            return []
    
    def _extract_contract_data_real(self) -> dict:
        """Extrair dados de contrato - VERS√ÉO QUE FUNCIONA"""
        try:
            logger.info("üîÑ Extraindo dados de contrato REAIS...")
            
            # Usar o m√©todo correto do GoogleSheetsService
            df = self._read_tab_dataframe("contract", "Informa√ß√µes de contrato")
            
            if df is None or df.empty:
                logger.warning("‚ö†Ô∏è DataFrame vazio da aba Informa√ß√µes de contrato")
                return self._get_default_contract()
            
            logger.info(f"‚úÖ DataFrame de contrato carregado: {len(df)} linhas")
            logger.info(f"üìä Colunas de contrato: {list(df.columns)}")
            
            # Converter para dicion√°rio
            contract_dict = {}
            for index, row in df.iterrows():
                try:
                    if len(row) >= 2:
                        key = str(row.iloc[0]).strip()
                        value = str(row.iloc[1]).strip()
                        if key and value and value != 'nan':
                            contract_dict[key] = value
                            logger.info(f"‚úÖ Contrato: {key} = {value}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Erro ao processar linha de contrato {index}: {e}")
                    continue
            
            # Processar dados de contrato
            result = {
                "client": self.config.client,
                "campaign": self.config.campaign,
                "investment": self._safe_float(contract_dict.get("Valor investido", 31000)),
                "cpv_contracted": self._safe_float(contract_dict.get("CPV", 0.16)),
                "complete_views_contracted": self._safe_int(contract_dict.get("Visualiza√ß√µes completas", 193750)),
                "impressions_contracted": self._safe_int(contract_dict.get("Impress√µes", 193750)),
                "period": contract_dict.get("Periodo de veicula√ß√£o", "15/09/2025 - 30/09/2025"),
                "status": "Em andamento"
            }
            
            logger.info("‚úÖ Dados de contrato extra√≠dos com SUCESSO")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao extrair dados de contrato REAIS: {e}")
            import traceback
            logger.error(f"‚ùå Traceback: {traceback.format_exc()}")
            return self._get_default_contract()
    
    def _calculate_total_metrics(
        self,
        daily_data: list,
        contract_data: Optional[Dict[str, Any]] = None,
    ) -> dict:
        """Calcular m√©tricas totais dos dados di√°rios"""
        try:
            if not daily_data:
                return {}

            # Somar todas as m√©tricas
            total_spend = sum(record.get("spend", 0) for record in daily_data)
            total_impressions = sum(record.get("impressions", 0) for record in daily_data)
            total_clicks = sum(record.get("clicks", 0) for record in daily_data)
            total_starts = sum(record.get("starts", 0) for record in daily_data)
            total_q100 = sum(record.get("q100", 0) for record in daily_data)

            # Calcular m√©tricas derivadas
            ctr = (total_clicks / total_impressions * 100) if total_impressions > 0 else 0
            cpm = (total_spend / total_impressions * 1000) if total_impressions > 0 else 0
            vtr = (total_starts / total_impressions * 100) if total_impressions > 0 else 0
            cpv = (total_spend / total_q100) if total_q100 > 0 else 0

            # Calcular pacing
            contract_data = contract_data or {}
            default_contract = self._get_default_contract()

            budget_contracted_raw = contract_data.get("investment")
            if budget_contracted_raw in (None, "", 0):
                budget_contracted_raw = default_contract.get("investment")
            budget_contracted = self._safe_float(budget_contracted_raw)

            complete_views_target_raw = contract_data.get("complete_views_contracted")
            if complete_views_target_raw in (None, "", 0):
                complete_views_target_raw = default_contract.get("complete_views_contracted")
            complete_views_target = self._safe_int(complete_views_target_raw)

            pacing = (total_spend / budget_contracted * 100) if budget_contracted > 0 else 0
            vc_pacing = (total_q100 / complete_views_target * 100) if complete_views_target > 0 else 0

            logger.info(f"‚úÖ M√©tricas calculadas: R$ {total_spend}, {total_impressions} impress√µes")

            return {
                "spend": total_spend,
                "impressions": total_impressions,
                "clicks": total_clicks,
                "starts": total_starts,
                "q100": total_q100,
                "ctr": ctr,
                "cpm": cpm,
                "vtr": vtr,
                "cpv": cpv,
                "pacing": pacing,
                "vc_pacing": vc_pacing
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao calcular m√©tricas totais: {e}")
            return {}
    
    def _get_publishers(self, daily_data: list) -> list:
        """Extrair publishers √∫nicos dos dados di√°rios"""
        try:
            publishers_list = []
            seen_names = set()

            for record in daily_data:
                raw_name = record.get("publisher") or record.get("site") or record.get("channel") or record.get("creative")
                publisher_name = _normalize_sheet_value(raw_name) or "Desconhecido"
                normalized_name = publisher_name.lower()

                if normalized_name in seen_names:
                    continue

                seen_names.add(normalized_name)

                entry = {"name": publisher_name}
                publisher_type = record.get("publisher_type")
                if publisher_type:
                    entry["type"] = publisher_type
                else:
                    entry["type"] = f"Site: {_slugify_publisher(publisher_name)}.com"

                publishers_list.append(entry)

            if not publishers_list:
                publishers_list.append({"name": "Publisher Padr√£o", "type": "Site: publisher-padrao.com"})

            logger.info(f"‚úÖ Publishers extra√≠dos: {len(publishers_list)}")
            return publishers_list

        except Exception as e:
            logger.error(f"‚ùå Erro ao extrair publishers: {e}")
            return [{"name": "Publisher Padr√£o", "type": "Site: publisher-padrao.com"}]
    
    def _get_default_contract(self) -> dict:
        """Retornar dados de contrato padr√£o"""
        return {
            "client": self.config.client,
            "campaign": self.config.campaign,
            "investment": 31000,
            "cpv_contracted": 0.16,
            "complete_views_contracted": 193750,
            "impressions_contracted": 193750,
            "period": "15/09/2025 - 30/09/2025",
            "status": "Em andamento"
        }
    
    def _safe_float(self, value) -> float:
        """Converter valor para float de forma segura"""

        if hasattr(pd, "isna") and pd.isna(value):
            return 0.0
        return parse_safe_float(value)

    def _safe_int(self, value) -> int:
        """Converter valor para int de forma segura"""

        if hasattr(pd, "isna") and pd.isna(value):
            return 0
        return parse_safe_int(value)

def extract_campaign_data(campaign_key: str) -> Optional[Dict[str, Any]]:
    """Fun√ß√£o principal para extrair dados de uma campanha - VERS√ÉO QUE FUNCIONA"""
    try:
        from persistent_database import get_campaign_config
        
        config = get_campaign_config(campaign_key)
        if not config:
            logger.error(f"‚ùå Configura√ß√£o n√£o encontrada para campanha: {campaign_key}")
            return None
        
        extractor = WorkingVideoExtractor(config)
        return extractor.extract_data()
        
    except Exception as e:
        logger.error(f"‚ùå Erro na fun√ß√£o principal: {e}")
        import traceback
        logger.error(f"‚ùå Traceback: {traceback.format_exc()}")
        return None
