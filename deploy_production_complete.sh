#!/bin/bash

echo "ðŸš€ DEPLOY COMPLETO PARA PRODUÃ‡ÃƒO"
echo "========================================"
echo ""
echo "âš ï¸  ATENÃ‡ÃƒO: Este script irÃ¡:"
echo "   1. Fazer backup dos dados atuais de produÃ§Ã£o"
echo "   2. Limpar dados de produÃ§Ã£o"
echo "   3. Fazer deploy do cÃ³digo atualizado"
echo "   4. Recriar todos os dashboards a partir do CSV"
echo ""
read -p "Deseja continuar? (sim/nÃ£o): " confirm

if [ "$confirm" != "sim" ]; then
    echo "âŒ Deploy cancelado pelo usuÃ¡rio"
    exit 1
fi

echo ""
echo "ðŸ“Š PASSO 1: BACKUP DOS DADOS DE PRODUÃ‡ÃƒO"
echo "========================================"
python3 backup_production_data.py
if [ $? -ne 0 ]; then
    echo "âŒ Erro ao fazer backup. Deploy cancelado por seguranÃ§a."
    exit 1
fi

echo ""
echo "ðŸ§¹ PASSO 2: LIMPANDO DADOS DE PRODUÃ‡ÃƒO"
echo "========================================"
echo "âš ï¸  Limpando BigQuery e Firestore de PRODUÃ‡ÃƒO..."

# Criar script de limpeza de produÃ§Ã£o
cat > clean_production_data.py << 'EOF'
#!/usr/bin/env python3

import os
from google.cloud import bigquery
from google.cloud import firestore

# Configurar para produÃ§Ã£o
os.environ['PROJECT_ID'] = 'automatizar-452311'
os.environ['ENVIRONMENT'] = 'production'

def main():
    try:
        print('ðŸ§¹ LIMPANDO DADOS DE PRODUÃ‡ÃƒO')
        print('=' * 50)
        
        # Conectar aos serviÃ§os
        bq_client = bigquery.Client()
        firestore_client = firestore.Client()
        
        # ConfiguraÃ§Ãµes de produÃ§Ã£o
        prod_dataset = 'south_media_dashboards'
        prod_campaigns_collection = 'campaigns'
        prod_dashboards_collection = 'dashboards'
        
        print(f'ðŸŽ¯ Limpando ambiente: PRODUCTION')
        print(f'ðŸ“Š Dataset BigQuery: {prod_dataset}')
        print(f'ðŸ“Š ColeÃ§Ãµes Firestore: {prod_campaigns_collection}, {prod_dashboards_collection}')
        
        # 1. LIMPAR BIGQUERY PRODUÃ‡ÃƒO
        print('\nðŸ“Š LIMPANDO BIGQUERY PRODUÃ‡ÃƒO...')
        
        tables_to_clear = ['campaigns', 'dashboards', 'metrics']
        
        for table in tables_to_clear:
            try:
                print(f'  ðŸ—‘ï¸ Limpando tabela: {table}')
                clear_query = f"DELETE FROM `automatizar-452311.{prod_dataset}.{table}` WHERE TRUE"
                result = bq_client.query(clear_query)
                result.result()  # Aguardar conclusÃ£o
                print(f'  âœ… Tabela {table} limpa')
            except Exception as e:
                print(f'  âš ï¸ Tabela {table} nÃ£o existe ou erro: {e}')
        
        # 2. LIMPAR FIRESTORE PRODUÃ‡ÃƒO
        print('\nðŸ“Š LIMPANDO FIRESTORE PRODUÃ‡ÃƒO...')
        
        collections_to_clear = [prod_campaigns_collection, prod_dashboards_collection]
        
        for collection_name in collections_to_clear:
            try:
                print(f'  ðŸ—‘ï¸ Limpando coleÃ§Ã£o: {collection_name}')
                collection = firestore_client.collection(collection_name)
                docs = collection.stream()
                
                deleted_count = 0
                for doc in docs:
                    doc.reference.delete()
                    deleted_count += 1
                
                print(f'  âœ… ColeÃ§Ã£o {collection_name} limpa ({deleted_count} documentos removidos)')
                
            except Exception as e:
                print(f'  âŒ Erro ao limpar coleÃ§Ã£o {collection_name}: {e}')
        
        print('\nðŸŽ‰ LIMPEZA DE PRODUÃ‡ÃƒO CONCLUÃDA!')
        
    except Exception as e:
        print(f'âŒ Erro na limpeza: {e}')
        import traceback
        traceback.print_exc()
        exit(1)

if __name__ == '__main__':
    main()
EOF

python3 clean_production_data.py
if [ $? -ne 0 ]; then
    echo "âŒ Erro ao limpar dados. Deploy cancelado."
    exit 1
fi

echo ""
echo "ðŸ—ï¸  PASSO 3: FAZENDO DEPLOY DO CÃ“DIGO"
echo "========================================"
./deploy_gen_dashboard_ia.sh
if [ $? -ne 0 ]; then
    echo "âŒ Erro no deploy. Verifique os logs."
    exit 1
fi

echo ""
echo "â³ Aguardando serviÃ§o estabilizar (30 segundos)..."
sleep 30

echo ""
echo "ðŸ“Š PASSO 4: RECRIANDO DASHBOARDS A PARTIR DO CSV"
echo "========================================"

# Criar script de automaÃ§Ã£o para produÃ§Ã£o
cat > automate_production_dashboards.py << 'EOF'
#!/usr/bin/env python3

import csv
import time
import requests
import logging

# ConfiguraÃ§Ã£o de logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

PRODUCTION_URL = "https://gen-dashboard-ia-6f3ckz7c7q-uc.a.run.app"

def read_csv_data(csv_file="dashboards.csv"):
    """Ler dados do arquivo CSV"""
    try:
        dashboards = []
        with open(csv_file, 'r', encoding='utf-8') as file:
            reader = csv.DictReader(file)
            for row in reader:
                # Extrair ID da planilha da URL
                sheet_url = row['planilha']
                sheet_id = sheet_url.split('/d/')[1].split('/')[0] if '/d/' in sheet_url else sheet_url
                
                # Gerar campaign_key
                campaign_key = f"{row['cliente'].lower().replace(' ', '_')}_{row['campanha'].lower().replace(' ', '_').replace(' ', '_')}"
                campaign_key = ''.join(c for c in campaign_key if c.isalnum() or c in ['_', '-'])[:100]
                
                dashboard_data = {
                    'campaign_key': campaign_key,
                    'client': row['cliente'].strip(),
                    'campaign_name': row['campanha'].strip(),
                    'sheet_id': sheet_id,
                    'channel': row['canal'].strip(),
                    'kpi': row['kpi'].strip().upper()
                }
                dashboards.append(dashboard_data)
        
        logger.info(f"ðŸ“Š {len(dashboards)} dashboards carregados do CSV")
        return dashboards
        
    except Exception as e:
        logger.error(f"âŒ Erro ao ler CSV: {e}")
        return []

def generate_dashboard_via_api(dashboard_data):
    """Gerar dashboard via API"""
    try:
        logger.info(f"ðŸš€ Gerando: {dashboard_data['client']} - {dashboard_data['campaign_name']}")
        
        response = requests.post(
            f"{PRODUCTION_URL}/api/generate-dashboard",
            json=dashboard_data,
            timeout=300
        )
        
        if response.status_code == 200:
            result = response.json()
            if result.get('success'):
                logger.info(f"âœ… Dashboard criado: {dashboard_data['campaign_key']}")
                return True, dashboard_data['campaign_key']
            else:
                logger.error(f"âŒ Erro na API: {result.get('message', 'Erro desconhecido')}")
                return False, None
        else:
            logger.error(f"âŒ Erro HTTP {response.status_code}")
            return False, None
                
    except Exception as e:
        logger.error(f"âŒ Erro ao gerar dashboard: {e}")
        return False, None

def main():
    logger.info("ðŸ¤– CRIANDO DASHBOARDS EM PRODUÃ‡ÃƒO")
    logger.info("=" * 60)
    
    # Ler dados do CSV
    dashboards = read_csv_data()
    if not dashboards:
        logger.error("âŒ Nenhum dashboard encontrado no CSV")
        return False
    
    # EstatÃ­sticas
    total = len(dashboards)
    success_count = 0
    failed_count = 0
    failed_dashboards = []
    
    logger.info(f"ðŸ“Š Total de dashboards para criar: {total}")
    
    # Gerar cada dashboard
    for i, dashboard_data in enumerate(dashboards, 1):
        logger.info(f"\nðŸ”„ [{i}/{total}] Processando...")
        
        success, campaign_key = generate_dashboard_via_api(dashboard_data)
        
        if success:
            success_count += 1
        else:
            failed_count += 1
            failed_dashboards.append(dashboard_data)
        
        # Pausa entre requests
        if i < total:
            time.sleep(2)
    
    # RelatÃ³rio final
    logger.info("\n" + "=" * 60)
    logger.info("ðŸ“Š RELATÃ“RIO FINAL")
    logger.info("=" * 60)
    logger.info(f"âœ… Dashboards criados com sucesso: {success_count}")
    logger.info(f"âŒ Dashboards que falharam: {failed_count}")
    logger.info(f"ðŸ“Š Taxa de sucesso: {(success_count/total)*100:.1f}%")
    
    if failed_dashboards:
        logger.info("\nâŒ DASHBOARDS QUE FALHARAM:")
        for dashboard in failed_dashboards:
            logger.info(f"  - {dashboard['client']} - {dashboard['campaign_name']}")
    
    return success_count == total

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
EOF

python3 automate_production_dashboards.py
if [ $? -ne 0 ]; then
    echo "âš ï¸ Alguns dashboards falharam. Verifique os logs."
fi

echo ""
echo "âœ… DEPLOY EM PRODUÃ‡ÃƒO CONCLUÃDO!"
echo "========================================"
echo ""
echo "ðŸ”— URLs de ProduÃ§Ã£o:"
echo "  ðŸ  Home: https://gen-dashboard-ia-6f3ckz7c7q-uc.a.run.app/"
echo "  ðŸ“‹ Lista: https://gen-dashboard-ia-6f3ckz7c7q-uc.a.run.app/dashboards-list"
echo "  ðŸ¥ Health: https://gen-dashboard-ia-6f3ckz7c7q-uc.a.run.app/health"
echo ""
echo "ðŸ“Š PrÃ³ximos passos:"
echo "  1. Verifique a listagem de dashboards"
echo "  2. Teste alguns dashboards aleatÃ³rios"
echo "  3. Confirme que os filtros estÃ£o funcionando"
echo ""

# Limpar scripts temporÃ¡rios
rm -f clean_production_data.py automate_production_dashboards.py

echo "ðŸŽ‰ Deploy completo finalizado!"

